{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_pca_with_svd.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starkdg/pyConvnetPhash/blob/master/train_pca_with_svd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jjcK55t-TFMq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "model_dir = \"/gdrive/My Drive/models\"\n",
        "module_inception_url = \"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1\"\n",
        "module_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/2\"\n",
        "\n",
        "module = hub.Module(module_url)\n",
        "target_height, target_width = hub.get_expected_image_size(module)\n",
        "\n",
        "n_inputs = 1792\n",
        "ndims = 256\n",
        "\n",
        "# location of testing .tfrecord files\n",
        "training_files_dir = \"/gdrive/My Drive/imageset/train\"\n",
        "validation_files_dir = \"/gdrive/My Drive/imageset/validation\"\n",
        "testing_files_dir = \"/gdrive/My Drive/imageset/test\"\n",
        "\n",
        "batch_size = 500\n",
        "norm_constant = 5.0               # input normalization constant (divide input features by)\n",
        "\n",
        "# location and file of exported frozen model file\n",
        "frozen_model = \"/gdrive/My Drive/models/svd/mobilenetv2_pca_from_svd_{0}to{1}_frozen_model.pb\".format(n_inputs, ndims)\n",
        "\n",
        "print(\"module: \", module_url)\n",
        "print(\"target height: \", target_height)\n",
        "print(\"target width: \", target_height)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ih_PGfUWLF95",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_tfrecord_files(path):\n",
        "  files = []\n",
        "  for entry in os.scandir(path):\n",
        "    if entry.is_file() and entry.name.endswith('.tfrecord'):\n",
        "             files.append(entry.path)\n",
        "  return files\n",
        "  \n",
        "  \n",
        "def _parse_example(example):\n",
        "  features = {'height': tf.FixedLenFeature([], tf.int64),\n",
        "              'width': tf.FixedLenFeature([], tf.int64),\n",
        "              'image_raw': tf.FixedLenFeature([], tf.string)}\n",
        "  parsed_features = tf.parse_single_example(example, features)\n",
        "  img = tf.io.decode_raw(parsed_features['image_raw'], tf.uint8)\n",
        "  height = tf.cast(parsed_features['height'], tf.int32)\n",
        "  width = tf.cast(parsed_features['width'], tf.int32)\n",
        "\n",
        "  img_reshaped = tf.manip.reshape(img, [height, width, 3])\n",
        "  imgfl = tf.image.convert_image_dtype(img_reshaped, dtype=tf.float32)\n",
        "  img_norm = tf.expand_dims(imgfl, 0)\n",
        "  img_resized = tf.image.resize_bicubic(img_norm, [target_height, target_width])\n",
        "  img_resized = tf.squeeze(img_resized, 0)\n",
        "  return img_resized\n",
        "\n",
        "\n",
        "def input_function(path, batch_size=1, num_epochs=None, shuffle=False):\n",
        "  tfrecords = get_tfrecord_files(path)\n",
        "  dataset = tf.data.TFRecordDataset(tfrecords)\n",
        "  dataset = dataset.map(_parse_example)\n",
        "  if (shuffle):\n",
        "    dataset = dataset.shuffle(10000)\n",
        "  dataset = dataset.batch(batch_size).repeat(num_epochs)\n",
        "  iterator = dataset.make_initializable_iterator()\n",
        "  return iterator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xd_MYyIBcgcy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_pca_model():\n",
        "\n",
        "  x = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"input\")  \n",
        "    \n",
        "  with tf.variable_scope(\"weights\", reuse=tf.AUTO_REUSE):\n",
        "    wts = tf.get_variable('w', initializer=tf.zeros(shape=(n_inputs, n_inputs), dtype=tf.float32))\n",
        "    \n",
        "  # input_dims -> ndims\n",
        "  output    = tf.matmul(x, wts, name=\"output\")\n",
        "  output512 = tf.matmul(x, tf.slice(wts, [0,0], [n_inputs, 512]), name='output512')\n",
        "  output256 = tf.matmul(x, tf.slice(wts, [0,0], [n_inputs, 256]), name='output256')\n",
        "  output128 = tf.matmul(x, tf.slice(wts, [0,0], [n_inputs, 128]), name='output128')\n",
        "  output64  = tf.matmul(x, tf.slice(wts, [0,0], [n_inputs,  64]), name='output64')\n",
        "  output32  = tf.matmul(x, tf.slice(wts, [0,0], [n_inputs,  32]), name='output32')  \n",
        "  \n",
        "  return wts, output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vss9wiXyStiY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def covariance(x):\n",
        "  mean_x = tf.reduce_mean(x, axis=0, keep_dims=True)\n",
        "  mx = tf.matmul(tf.transpose(mean_x), mean_x)\n",
        "  vx = tf.matmul(tf.transpose(x), x)/tf.cast(tf.shape(x)[0]-1, tf.float32)\n",
        "  cov_xx = vx - mx\n",
        "  return cov_xx "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p8BcbOitLQ5l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_pca_model(training_files_dir, batch_size):\n",
        "\n",
        "  wts, output = create_pca_model()  \n",
        "   \n",
        "  training_iter = input_function(training_files_dir, batch_size)\n",
        "  training_images = training_iter.get_next()\n",
        "  training_features = module(training_images)\n",
        "  \n",
        "  cov_mat = covariance(training_features)\n",
        "  s, u, v = tf.linalg.svd(cov_mat, full_matrices=True, compute_uv=True)\n",
        "  new_wts = tf.assign(wts, tf.transpose(u))\n",
        "  cumsum_s = tf.math.cumsum(s) / tf.math.reduce_max(s)\n",
        "  \n",
        "  # execute graph\n",
        "  print(\"Train PCA by SVD\")\n",
        "  init = tf.global_variables_initializer()\n",
        "  sess = tf.Session()\n",
        "  sess.run(init)\n",
        "  sess.run([training_iter.initializer])\n",
        "  features = sess.run(training_features)\n",
        "  features = sess.run(training_features)\n",
        "  cs, w = sess.run([cumsum_s, new_wts])\n",
        "   \n",
        "  plt.figure(1)\n",
        "  plt.plot(cs)\n",
        "  plt.xlabel('no. leading eigen vectors')\n",
        "  plt.ylabel('cumulative sum')\n",
        "  plt.title('Cumulative Sum of Leading Eigen Vectors')\n",
        "  plt.show()\n",
        "    \n",
        "  plt.figure(2)\n",
        "  plt.hist(w.ravel(), bins=100, histtype='bar')\n",
        "  plt.title('histogram of weights')\n",
        "  plt.show()\n",
        "    \n",
        "\n",
        "  print(\"freeze graph ...\")  \n",
        "  out_nodes = ['output', 'output512', 'output256', 'output128', 'output64', 'output32']\n",
        "  graphdef = tf.get_default_graph().as_graph_def()\n",
        "  subgraphdef = tf.compat.v1.graph_util.extract_sub_graph(graphdef, out_nodes)\n",
        "  subgraphdef_frozen = tf.compat.v1.graph_util.convert_variables_to_constants(sess, subgraphdef, out_nodes)\n",
        "    \n",
        "  print(\"write model: \", frozen_model)\n",
        "  with tf.gfile.GFile(frozen_model, \"wb\") as f:\n",
        "    f.write(subgraphdef_frozen.SerializeToString())\n",
        "    \n",
        "  sess.close() \n",
        "   \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Is7JSNCDLWpG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Train autoencoder\")\n",
        "print(\"training files: \", training_files_dir)\n",
        "print(\"batch size: \", batch_size)\n",
        "\n",
        "train_pca_model(training_files_dir, batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}